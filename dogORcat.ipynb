{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle \n",
    "from tqdm import tqdm   \n",
    "\n",
    "TRAIN_DIR = 'train'\n",
    "TEST_DIR = 'test'\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '6conv-basic') # just so we remember which saved model is which, sizes must match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our first order of business is to convert the images and labels to array information that we can pass through our network. To do this, we'll need a helper function to convert the image name to an array. \n",
    "\n",
    "Our images are labeled like \"cat.1\" or \"dog.3\" and so on, so we can just split out the dog/cat, and then convert to an array like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [cat,dog]\n",
    "    #                            [much cat, no dog]\n",
    "    if word_label == 'cat': return [1,0]\n",
    "    #                             [no cat, very doggo]\n",
    "    elif word_label == 'dog': return [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build another function to fully process the training images and their labels into arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = create_train_data()\n",
    "# If you have already created the dataset:\n",
    "train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([[65, 68, 68, ..., 60, 56, 56],\n",
       "       [72, 68, 76, ..., 62, 58, 58],\n",
       "       [76, 78, 72, ..., 66, 67, 60],\n",
       "       ...,\n",
       "       [41, 38, 34, ..., 51, 50, 51],\n",
       "       [32, 30, 36, ..., 35, 36, 41],\n",
       "       [30, 27, 34, ..., 36, 38, 31]], dtype=uint8),\n",
       "        array([1, 0])],\n",
       "       [array([[169, 169, 168, ..., 164, 172, 167],\n",
       "       [171, 171, 173, ..., 181, 170, 170],\n",
       "       [171, 173, 173, ..., 178, 180, 176],\n",
       "       ...,\n",
       "       [100, 133, 166, ..., 167, 168, 166],\n",
       "       [ 99, 125, 149, ..., 168, 168, 172],\n",
       "       [118, 110, 127, ..., 168, 167, 162]], dtype=uint8),\n",
       "        array([1, 0])],\n",
       "       [array([[26, 26, 26, ...,  2, 13, 17],\n",
       "       [26, 26, 26, ..., 15, 16,  2],\n",
       "       [26, 26, 26, ...,  9, 14,  7],\n",
       "       ...,\n",
       "       [18, 19, 22, ..., 16, 16, 16],\n",
       "       [22, 22, 22, ..., 17, 14, 14],\n",
       "       [21, 23, 22, ..., 17, 16, 16]], dtype=uint8),\n",
       "        array([1, 0])],\n",
       "       ...,\n",
       "       [array([[ 32,  71, 103, ..., 147, 148, 128],\n",
       "       [195, 130,  43, ..., 144, 146, 118],\n",
       "       [197,  68,  39, ..., 147, 148, 105],\n",
       "       ...,\n",
       "       [ 67,  23,  33, ..., 101, 119, 112],\n",
       "       [ 43,  60,  33, ..., 150, 151, 153],\n",
       "       [ 42,  61,  31, ..., 147, 143, 136]], dtype=uint8),\n",
       "        array([1, 0])],\n",
       "       [array([[ 59,  50,  89, ..., 182, 120,  33],\n",
       "       [ 32,  33,  82, ..., 183, 204, 248],\n",
       "       [ 45,  80,  70, ..., 214, 237, 193],\n",
       "       ...,\n",
       "       [168, 175, 177, ..., 159, 139, 148],\n",
       "       [164, 177, 173, ..., 148, 154, 161],\n",
       "       [171, 173, 173, ..., 170, 159, 156]], dtype=uint8),\n",
       "        array([0, 1])],\n",
       "       [array([[160, 164, 161, ..., 158, 160, 161],\n",
       "       [161, 165, 157, ..., 153, 154, 148],\n",
       "       [154, 158, 160, ..., 165, 159, 160],\n",
       "       ...,\n",
       "       [141, 146, 152, ...,  82,  69,  61],\n",
       "       [128, 145, 141, ..., 121, 117, 115],\n",
       "       [136, 136, 139, ..., 117, 119, 121]], dtype=uint8),\n",
       "        array([0, 1])]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Next, we're ready to define our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have here is a nice, 3layered convolutional neural network, with a fully connected layer, and then the output layer. It's been debated whether or not a fully connected layer is of any use. I'll leave it in anyway. \n",
    "\n",
    "This exact convnet was good enough for recognizing hand 28x28 written digits. Let's see how it does with cats and dogs at 50x50 resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split out training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the training data and testing data are both labeled datasets. The training data is what we'll fit the neural network with, and the test data is what we're going to use to validate the results. The test data will be \"out of sample,\" meaning the testing data will only be used to test the accuracy of the network, not to train it. \n",
    "\n",
    "We also have \"test\" images that we downloaded. THOSE images are not labeled at all, and those are what we'll submit to Kaggle for the competition.\n",
    "\n",
    "Next, we're going to create our data arrays. For some reason, typical numpy logic like:\n",
    "\n",
    "array[:,0] and array[:,1] did NOT work for me here. Not sure what I'm doing wrong, so I do this instead to separate my features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit for 3 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1148  | total loss: \u001b[1m\u001b[32m0.69346\u001b[0m\u001b[0m | time: 68.591s\n",
      "| Adam | epoch: 003 | loss: 0.69346 - acc: 0.4806 -- iter: 24448/24500\n",
      "Training Step: 1149  | total loss: \u001b[1m\u001b[32m0.69351\u001b[0m\u001b[0m | time: 69.771s\n",
      "| Adam | epoch: 003 | loss: 0.69351 - acc: 0.4747 | val_loss: 0.69293 - val_acc: 0.5220 -- iter: 24500/24500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could keep trying, but, if you haven't made accuracy progress in the first 3 epochs, you're probably not going to at all, unless it's due to overfitment...at least in my experience. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're gonna need a bigger network\n",
    "\n",
    "First, we need to reset the graph instance, since we're doing this in a continuous environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2416  | total loss: \u001b[1m\u001b[32m0.42335\u001b[0m\u001b[0m | time: 22.212s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 007 | loss: 0.42335 - acc: 0.8041 -- iter: 07552/24500\n"
     ]
    }
   ],
   "source": [
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can be too big #\n",
    "\n",
    "Bigger is not always better, there does get to be a limit, at least from my experience. A bigger network figures things out better, and quicker, but tends to also overfit the training data. You can use dropout (sets randomly a certain % of nodes to not take part in the network for more robusts networks) to rectify this slightly, but there does seem to be a limit. \n",
    "\n",
    "Okay, now what? Let's see how we've done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visually inspecting our network against unlabeled data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = process_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4198\n",
      "[[ 15  17  17 ...   3   3   3]\n",
      " [ 15  17  17 ...   3   3   3]\n",
      " [ 13  17  17 ...   3   3   2]\n",
      " ...\n",
      " [ 12  10 100 ... 172   0   7]\n",
      " [ 11  10 110 ...   9   8   9]\n",
      " [  8  24 133 ...  27  12  14]]\n",
      "6038\n",
      "[[ 42  53  53 ...  65  63  58]\n",
      " [ 50  53  50 ...  63  62  53]\n",
      " [ 53  58  67 ...  58  63  63]\n",
      " ...\n",
      " [102 113 117 ... 119 120 123]\n",
      " [105 109 114 ... 141 118 122]\n",
      " [115 113 105 ... 137 122 158]]\n",
      "6541\n",
      "[[119 198 105 ...  79 118  21]\n",
      " [122 190 117 ...  43  47  56]\n",
      " [123 194 142 ... 140  20  60]\n",
      " ...\n",
      " [171 183 179 ... 110 102  75]\n",
      " [173 176 178 ... 114 115 101]\n",
      " [166 171 171 ... 120 116 117]]\n",
      "6101\n",
      "[[253 253 253 ... 253 253 253]\n",
      " [253 253 253 ... 253 253 253]\n",
      " [253 253 253 ... 253 253 253]\n",
      " ...\n",
      " [253 253 253 ... 253 253 253]\n",
      " [253 253 253 ... 253 253 253]\n",
      " [253 253 253 ... 253 253 253]]\n",
      "2965\n",
      "[[191 191 189 ... 229 229 229]\n",
      " [192 191 190 ... 229 229 229]\n",
      " [193 192 191 ... 229 229 229]\n",
      " ...\n",
      " [  8   9 107 ... 163 178 150]\n",
      " [ 11 101 154 ... 169 155 153]\n",
      " [ 90 160 186 ... 154 133 121]]\n",
      "4786\n",
      "[[ 37  38  44 ...  95  99  96]\n",
      " [ 34  34  41 ...  96  94  94]\n",
      " [ 33  35  41 ... 101  96  98]\n",
      " ...\n",
      " [157 155 157 ... 167 171 169]\n",
      " [154 152 160 ... 170 170 170]\n",
      " [161 157 162 ... 171 167 172]]\n",
      "9453\n",
      "[[ 96  94  48 ...  67  63  51]\n",
      " [ 59  88  91 ...  65  59  54]\n",
      " [ 96  86  83 ...  66  69  59]\n",
      " ...\n",
      " [114 122 108 ...  64  65  53]\n",
      " [116 120 118 ...  67  65  64]\n",
      " [116 120 114 ...  61  58  57]]\n",
      "6719\n",
      "[[ 45  49  47 ...  51  51  56]\n",
      " [ 42  41  41 ...  52  54  58]\n",
      " [ 51  50  47 ...  51  52  55]\n",
      " ...\n",
      " [132 141 155 ... 125  90  59]\n",
      " [129 156 172 ... 142 138 137]\n",
      " [146 135 151 ... 152 140 132]]\n",
      "10938\n",
      "[[231 226 228 ... 243 244 244]\n",
      " [227 230 229 ... 242 244 243]\n",
      " [228 228 228 ... 242 241 243]\n",
      " ...\n",
      " [168 162 167 ... 182 178 178]\n",
      " [168 160 165 ... 186 182 184]\n",
      " [172 174 171 ... 137 148 155]]\n",
      "9426\n",
      "[[167 165 168 ...  34  33  32]\n",
      " [169 172 165 ...  34  32  31]\n",
      " [171 175 167 ...  38  35  33]\n",
      " ...\n",
      " [107 105  97 ...  58  39  56]\n",
      " [109 101 104 ...  40  46  54]\n",
      " [100  97 108 ...  54  32  44]]\n",
      "887\n",
      "[[ 66  69  67 ...  89  87  90]\n",
      " [ 69  71  71 ...  88  88  88]\n",
      " [ 74  72  72 ...  95  91  92]\n",
      " ...\n",
      " [127 133 130 ... 117 136 136]\n",
      " [129 130 129 ... 138 129 123]\n",
      " [133 128 128 ... 146 129 139]]\n",
      "1133\n",
      "[[  1   3   1 ...  56  49  66]\n",
      " [  1   3   1 ...  70  66  65]\n",
      " [ 48  81  45 ...  55  72  66]\n",
      " ...\n",
      " [175 177 189 ... 253 251 251]\n",
      " [168 176 184 ... 253 253 251]\n",
      " [156 163 176 ... 251 251 251]]\n"
     ]
    }
   ],
   "source": [
    "for num,data in enumerate(test_data[:12]):\n",
    "    print(data[1])\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-625e4e0ac5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#model_out = model.predict([data])[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHUAAABjCAYAAACli086AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABLZJREFUeJztnUFoXFUUhr/f1ipkYcFmIVqoxWLIwkU6SFZFEKHNIlnoIt3USCUULa4FF0I30pVQlJaIQeuiFruKoAii0FVrJ6C1VZRUEIOBpirZCNXAcfFeYxwnmTuT+2amh/PBwLy59905zMebvDnknCszI/DFPb0OIMhPSHVISHVISHVISHVISHVIS6mSZiXdlHRtg3FJOiVpQdJVSSP5wwzaIeVKfQ84uMn4IWBf+ZgGTm89rGArtJRqZheB3zeZMgGctYJLwE5JD+UKMGifHH9THwZ+WXe8WL4W9IjtGdZQk9ea5h4lTVN8RTMwMLB/aGgow9v7ZX5+/paZDbZ7Xg6pi8DudcePAL82m2hmM8AMQK1Ws3q9nuHt/SLp507Oy/H1OwccKe+CR4EVM1vKsG7QIS2vVEnngKeAXZIWgdeBewHM7AzwCTAGLAB/Ai9UFWyQRkupZna4xbgBL2eLKNgykVFySEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SEh1SJJUSQcl/VDWoL7aZHxK0rKkr8vHi/lDDVJJ+Q/9bcDbwDMUdTNXJM2Z2XcNU8+b2fEKYgzaJOVKfRJYMLOfzOwv4EOKmtSgT0mRmlp/+mzZHuCCpN1NxoMukSI1pf70Y2CPmT0BfA6833QhaVpSXVJ9eXm5vUiDZFKktqw/NbPfzOx2efgOsL/ZQmY2Y2Y1M6sNDrZdSxskkiL1CrBP0qOSdgCTFDWpazT0eBgHvs8XYtAuKaWMq5KOA58B24BZM7su6QRQN7M54BVJ48AqRdOPqQpjDlqgXrWGjfYArZE0b2a1ds+LjJJDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDQqpDctWn3ifpfDl+WdKe3IEG6aRsinunPvUQMAwcljTcMO0o8IeZPQa8CZzMHWiQTq761An+rXS7ADwtqVm1XNAFctWnrs0xs1VgBXgwR4BB+6RstZlSn5q0h+r6/VOB2xvtc94jdgG3eh1EA493clKK1JT9Ue/MWZS0HXiAJlter98/VVK9k+Kfqui3eKCIqZPzstSnlsfPl8+fA76wXpXTBdnqU98FPpC0QHGFTlYZdLA5PatPlTRdfh33Bf0WD3QeU8+kBtURaUKHVC6131KM/daST9KspJsb/bxTwaky3quSRlouamaVPShurG4Ae4EdwDfAcMOcl4Az5fNJinZ4vYxnCnirys+l4f0OACPAtQ3Gx4BPKXIBo8DlVmtWfaX2W4qx71rymdlFmvymX8cEcNYKLgE7G1oc/Y+qpfZbivFubMmXGvMaVUvNlmLMRLaWfF2k7c+naqntpBjZLMXYrXgssSVfF0n5DP9D1VL7LcV4N7bkmwOOlHfBo8CKmS1tekYX7u7GgB8p7jpfK187AYyXz+8HPgIWgK+AvT2O5w3gOsWd8ZfAUMXxnAOWgL8prsqjwDHgWDkuin9SuAF8C9RarRkZJYdERskhIdUhIdUhIdUhIdUhIdUhIdUhIdUh/wCJL53tcT5K8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f277a738898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "for num,data in enumerate(test_data[:12]):\n",
    "    # cat: [1,0]\n",
    "    # dog: [0,1]\n",
    "    \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,4,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    #model_out = model.predict([data])[0]\n",
    "    model_out = model.predict([data])[0]\n",
    "    print(model.predict([data]))\n",
    "    print(model.predict([data])[0])\n",
    "    print(np.argmax(model_out))\n",
    "    if np.argmax(model_out) == 1: str_label='Dog'\n",
    "    else: str_label='Cat'\n",
    "        \n",
    "    y.imshow(orig,cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so we made a couple mistakes, but not too bad actually! \n",
    "\n",
    "If you're happy with it, let's compete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:35<00:00, 349.71it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('submission_file.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
